{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patients = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - raw cleaned.csv', sep=';')  # cleaned data\n",
    "# df_patients = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - supercleaned.csv', sep=';')  # super cleaned data\n",
    "df_patients = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - Super cleaned testset.csv', sep=';')  # super cleaned testset\n",
    "df_patients['Bias'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(df, xcol, ycol, percentage):\n",
    "    allIndex = np.unique(df['pat'].tolist()) # Get all unique patients id's\n",
    "    random.seed(2) # Set random seeed so the answer is the same\n",
    "    \n",
    "    PercentageIndex = []\n",
    "    for i in np.unique(np.floor(allIndex / 1000)): # Cycle through each categorie (only cycles through the ones that are present)\n",
    "        CatPatients = allIndex[allIndex<((i+1)*1000)] # Filters out patients who are bigger then our max\n",
    "        CatPatients = CatPatients[CatPatients>=((i)*1000)] # Filters out patients that are smaller\n",
    "        \n",
    "        AmountItems = len(CatPatients)\n",
    "        AmountRandom = math.floor(AmountItems*percentage)\n",
    "        PercentageIndex.extend(random.sample(list(CatPatients), AmountRandom))        \n",
    "        \n",
    "    AmountItems = len(allIndex)\n",
    "    AmountRandom = math.floor(AmountItems*percentage)\n",
    "    \n",
    "    PercentageIndex = random.sample(list(allIndex), AmountRandom)\n",
    "    \n",
    "    # Normalize data\n",
    "    xcoldf = df[xcol]\n",
    "#     xcoldf = normalize(xcoldf)\n",
    "    \n",
    "    Percentagedf = xcoldf[df['pat'].isin(PercentageIndex)]\n",
    "    Percentagey = df[ycol][df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    Testdf = xcoldf[~df['pat'].isin(PercentageIndex)]\n",
    "    Testy = df[ycol][~df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    testpatlist = df['pat'][~df['pat'].isin(PercentageIndex)]\n",
    "    return (Percentagedf, Testdf, Percentagey, Testy, testpatlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns except three as X\n",
    "columns = list(df_patients.columns)\n",
    "# columns.remove('Unnamed: 0')\n",
    "columns.remove('cat')\n",
    "columns.remove('pat')\n",
    "param = columns\n",
    "\n",
    "Xcolumns = []\n",
    "Xcolumns.extend(param)\n",
    "\n",
    "X = df_patients[Xcolumns]\n",
    "y = df_patients[['cat']]\n",
    "\n",
    "# Split training set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, tmptestpatlist = SplitData(df_patients, Xcolumns, 'cat', 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Learn model\n",
    "lr = LogisticRegression(random_state=21)\n",
    "# lr = MLPClassifier(random_state=21,tol=0.00001,learning_rate='adaptive',verbose=10)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Predict test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.000     0.000     0.000        32\n",
      "           2      0.816     0.691     0.748       243\n",
      "           3      0.412     0.219     0.286        32\n",
      "           4      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.570     0.570     0.570       307\n",
      "   macro avg      0.307     0.228     0.259       307\n",
      "weighted avg      0.688     0.570     0.622       307\n",
      "\n",
      "175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(accuracy_score(y_test, y_pred, normalize=False, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pat\n",
       "1025    2.000000\n",
       "2013    1.773663\n",
       "3036    3.406250\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf = pd.DataFrame()\n",
    "tmpdf['pat'] = tmptestpatlist\n",
    "tmpdf['pred'] = y_pred\n",
    "tmpdf.groupby('pat')['pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "             Params     Theta  Absolute\n",
      "388  Delta_EnergyZR -0.006546  0.006546\n",
      "2    Alpha_EnergyXR  0.006499  0.006499\n",
      "3    Alpha_EnergyYR -0.006358  0.006358\n",
      "134  Bravo_EnergyYL -0.005600  0.005600\n",
      "6    Alpha_EnergyYL -0.005444  0.005444\n",
      "1\n",
      "               Params     Theta  Absolute\n",
      "517     Echo_EnergyXL  0.005290  0.005290\n",
      "135    Bravo_EnergyZL -0.004067  0.004067\n",
      "258  Charlie_EnergyXR -0.003348  0.003348\n",
      "263  Charlie_EnergyZL  0.003145  0.003145\n",
      "388    Delta_EnergyZR -0.002885  0.002885\n",
      "2\n",
      "             Params     Theta  Absolute\n",
      "135  Bravo_EnergyZL -0.006161  0.006161\n",
      "388  Delta_EnergyZR  0.004834  0.004834\n",
      "390  Delta_EnergyYL -0.004040  0.004040\n",
      "517   Echo_EnergyXL -0.003825  0.003825\n",
      "131  Bravo_EnergyYR  0.003069  0.003069\n",
      "3\n",
      "               Params     Theta  Absolute\n",
      "7      Alpha_EnergyZL -0.005693  0.005693\n",
      "258  Charlie_EnergyXR -0.005221  0.005221\n",
      "517     Echo_EnergyXL -0.004908  0.004908\n",
      "134    Bravo_EnergyYL  0.004238  0.004238\n",
      "2      Alpha_EnergyXR -0.003578  0.003578\n"
     ]
    }
   ],
   "source": [
    "for num, i in enumerate(lr.coef_):\n",
    "    print(num)\n",
    "    ParamCheck = pd.DataFrame()\n",
    "    ParamCheck['Params'] = Xcolumns\n",
    "    ParamCheck['Theta'] = list(i)\n",
    "    ParamCheck['Absolute'] = np.absolute(list(ParamCheck['Theta']))\n",
    "    ParamCheck = ParamCheck.sort_values(by=['Absolute'], ascending=False)\n",
    "    print(ParamCheck.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
