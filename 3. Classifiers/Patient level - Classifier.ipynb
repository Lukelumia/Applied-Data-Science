{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patients = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - raw cleaned.csv', sep=';')  # cleaned data\n",
    "df_patients = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - supercleaned.csv', sep=';')  # super cleaned data\n",
    "df_patients['Bias'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(df, xcol, ycol, percentage):\n",
    "    allIndex = np.unique(df['pat'].tolist()) # Get all unique patients id's\n",
    "    random.seed(2) # Set random seeed so the answer is the same\n",
    "    \n",
    "    PercentageIndex = []\n",
    "    for i in np.unique(np.floor(allIndex / 1000)): # Cycle through each categorie (only cycles through the ones that are present)\n",
    "        CatPatients = allIndex[allIndex<((i+1)*1000)] # Filters out patients who are bigger then our max\n",
    "        CatPatients = CatPatients[CatPatients>=((i)*1000)] # Filters out patients that are smaller\n",
    "        \n",
    "        AmountItems = len(CatPatients)\n",
    "        AmountRandom = math.floor(AmountItems*percentage)\n",
    "        PercentageIndex.extend(random.sample(list(CatPatients), AmountRandom))        \n",
    "        \n",
    "    AmountItems = len(allIndex)\n",
    "    AmountRandom = math.floor(AmountItems*percentage)\n",
    "    \n",
    "    PercentageIndex = random.sample(list(allIndex), AmountRandom)\n",
    "    \n",
    "    # Normalize data\n",
    "    xcoldf = df[xcol]\n",
    "#     xcoldf = normalize(xcoldf)\n",
    "    \n",
    "    Percentagedf = xcoldf[df['pat'].isin(PercentageIndex)]\n",
    "    Percentagey = df[ycol][df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    Testdf = xcoldf[~df['pat'].isin(PercentageIndex)]\n",
    "    Testy = df[ycol][~df['pat'].isin(PercentageIndex)]\n",
    "    \n",
    "    testpatlist = df['pat'][~df['pat'].isin(PercentageIndex)]\n",
    "    return (Percentagedf, Testdf, Percentagey, Testy, testpatlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns except three as X\n",
    "columns = list(df_patients.columns)\n",
    "# columns.remove('Unnamed: 0')\n",
    "columns.remove('cat')\n",
    "columns.remove('pat')\n",
    "param = columns\n",
    "\n",
    "Xcolumns = []\n",
    "Xcolumns.extend(param)\n",
    "\n",
    "X = df_patients[Xcolumns]\n",
    "y = df_patients[['cat']]\n",
    "\n",
    "# Split training set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, tmptestpatlist = SplitData(df_patients, Xcolumns, 'cat', 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Learn model\n",
    "lr = LogisticRegression(random_state=21)\n",
    "# lr = MLPClassifier(random_state=21,tol=0.00001,learning_rate='adaptive',verbose=10)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Predict test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     0.891     0.942       128\n",
      "           2      0.940     1.000     0.969      2016\n",
      "           3      0.745     1.000     0.854      1064\n",
      "           4      1.000     0.793     0.884      2304\n",
      "\n",
      "   micro avg      0.911     0.911     0.911      5512\n",
      "   macro avg      0.921     0.921     0.912      5512\n",
      "weighted avg      0.929     0.911     0.911      5512\n",
      "\n",
      "5019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(accuracy_score(y_test, y_pred, normalize=False, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pat\n",
       "1014    1.000000\n",
       "1016    1.437500\n",
       "1020    1.000000\n",
       "1029    1.000000\n",
       "2003    2.000000\n",
       "2012    2.000000\n",
       "2017    2.000000\n",
       "2020    2.125000\n",
       "2027    2.000000\n",
       "2028    2.000000\n",
       "2037    2.000000\n",
       "2038    2.000000\n",
       "3011    3.000000\n",
       "3013    3.000000\n",
       "3014    3.000000\n",
       "3016    3.000000\n",
       "3029    3.000000\n",
       "3032    3.000000\n",
       "3033    3.000000\n",
       "4012    3.524414\n",
       "4024    3.917187\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf = pd.DataFrame()\n",
    "tmpdf['pat'] = tmptestpatlist\n",
    "tmpdf['pred'] = y_pred\n",
    "tmpdf.groupby('pat')['pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "                  Params     Theta  Absolute\n",
      "0             Unnamed: 0 -0.013271  0.013271\n",
      "263     Charlie_EnergyYL -0.004250  0.004250\n",
      "389       Delta_EnergyZR -0.003396  0.003396\n",
      "195  Bravo_humerus_r_y_2  0.003309  0.003309\n",
      "7         Alpha_EnergyYL -0.003139  0.003139\n",
      "1\n",
      "                  Params     Theta  Absolute\n",
      "404  Delta_humerus_r_z_0  0.051867  0.051867\n",
      "416  Delta_humerus_l_z_0  0.048303  0.048303\n",
      "452  Delta_humerus_r_z_2 -0.045593  0.045593\n",
      "464  Delta_humerus_l_z_2 -0.044193  0.044193\n",
      "488  Delta_humerus_l_z_3 -0.031663  0.031663\n",
      "2\n",
      "                  Params     Theta  Absolute\n",
      "452  Delta_humerus_r_z_2  0.042820  0.042820\n",
      "416  Delta_humerus_l_z_0 -0.042365  0.042365\n",
      "464  Delta_humerus_l_z_2  0.031846  0.031846\n",
      "404  Delta_humerus_r_z_0 -0.030082  0.030082\n",
      "438  Delta_humerus_l_x_1  0.029019  0.029019\n",
      "3\n",
      "                    Params     Theta  Absolute\n",
      "67     Alpha_humerus_r_y_2 -0.007754  0.007754\n",
      "195    Bravo_humerus_r_y_2 -0.007538  0.007538\n",
      "274  Charlie_humerus_r_x_0  0.006622  0.006622\n",
      "260       Charlie_EnergyYR -0.006238  0.006238\n",
      "438    Delta_humerus_l_x_1 -0.005942  0.005942\n"
     ]
    }
   ],
   "source": [
    "for num, i in enumerate(lr.coef_):\n",
    "    print(num)\n",
    "    ParamCheck = pd.DataFrame()\n",
    "    ParamCheck['Params'] = Xcolumns\n",
    "    ParamCheck['Theta'] = list(i)\n",
    "    ParamCheck['Absolute'] = np.absolute(list(ParamCheck['Theta']))\n",
    "    ParamCheck = ParamCheck.sort_values(by=['Absolute'], ascending=False)\n",
    "    print(ParamCheck.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      1.000     0.983     0.992       832\n",
      "           2      0.993     1.000     0.996     17676\n",
      "           3      0.965     1.000     0.982      9956\n",
      "           4      1.000     0.977     0.989     21046\n",
      "\n",
      "   micro avg      0.990     0.990     0.990     49510\n",
      "   macro avg      0.989     0.990     0.990     49510\n",
      "weighted avg      0.990     0.990     0.990     49510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_testset = pd.read_csv('Data Alpha Bravo Charlie Delta Echo - Super cleaned testset.csv', sep=';')  # super cleaned testset\n",
    "\n",
    "testset_X = df_patients[Xcolumns]\n",
    "testset_y = df_patients[['cat']]\n",
    "\n",
    "y_pred_testset = lr.predict(testset_X)\n",
    "\n",
    "print(classification_report(testset_y, y_pred_testset, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
