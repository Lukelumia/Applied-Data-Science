{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeaderMaker(PatientFile):\n",
    "    df_cleaned = pd.read_csv('/data/ortho/testset/' + PatientFile, header=None)\n",
    "#     df_cleaned = pd.read_csv(PatientFile, header=None)\n",
    "\n",
    "    df_cleaned = df_cleaned.rename(columns={0: \"thorax_r_x\", 1: \"thorax_r_y\", 2: \"thorax_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={3: \"clavicula_r_x\", 4: \"clavicula_r_y\", 5: \"clavicula_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={6: \"scapula_r_x\", 7: \"scapula_r_y\", 8: \"scapula_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={9: \"humerus_r_x\", 10: \"humerus_r_y\", 11: \"humerus_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={12: \"ellebooghoek_r\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={15: \"thorax_l_x\", 16: \"thorax_l_y\", 17: \"thorax_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={18: \"clavicula_l_x\", 19: \"clavicula_l_y\", 20: \"clavicula_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={21: \"scapula_l_x\", 22: \"scapula_l_y\", 23: \"scapula_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={24: \"humerus_l_x\", 25: \"humerus_l_y\", 26: \"humerus_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={27: \"ellebooghoek_l\"})\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "def VisualizeItemCleaned(item, x, y, z):\n",
    "    global FileWithItemsToDelete\n",
    "    global FileWithItemsToAdjust\n",
    "    global FileWithItemsToSplitAgain\n",
    "    \n",
    "    \n",
    "    \n",
    "    FileName = item['FileName'].split('/')[5]\n",
    "    Split = item['Split']\n",
    "    JunkBefore = item['RemoveJunkBefore']\n",
    "    JunkAfter = item['RemoveJunkAfter']\n",
    "    User = item['User']\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        splitted = FileName.split('.')[0].split('_')\n",
    "        Cat = int(splitted[0].split('Cat')[1])\n",
    "        pat = int(splitted[1].split('pat')[1])\n",
    "        met = int(splitted[2].split('meting')[1])\n",
    "        oef = int(splitted[3].split('oef')[1])\n",
    "        titel = '%s %s %s %s by: %s' % (Cat, pat, met, oef, User)\n",
    "    except(IndexError):\n",
    "        oef = 'failed'\n",
    "        titel = oef\n",
    "\n",
    "    origdata = HeaderMaker(FileName)\n",
    "    MaxFrame = len(origdata) - 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    start = 0\n",
    "    end = MaxFrame + 1\n",
    "    \n",
    "    if (JunkBefore > 0 and JunkBefore < MaxFrame):\n",
    "#         plt.axvline(x=JunkBefore, color='b')\n",
    "        start = JunkBefore\n",
    "        \n",
    "    if (JunkAfter > 0 and JunkAfter < MaxFrame):\n",
    "#         plt.axvline(x=JunkAfter, color='g')\n",
    "        end = JunkAfter\n",
    "    data = origdata.iloc[start:end]\n",
    "        \n",
    "    if (Split > JunkBefore and Split < MaxFrame):\n",
    "        data = [data.iloc[:Split-JunkBefore], data.iloc[Split-JunkBefore:]]\n",
    "    else:\n",
    "        data = [data]\n",
    "    \n",
    "#     print(titel)\n",
    "    if ((Cat == 3) & (pat == 31) & (met == 1) & (oef == 5)):\n",
    "        print('Our oefening')\n",
    "    \n",
    "    \n",
    "    for num, plaatje in enumerate(data):\n",
    "        splitnum = num + 1\n",
    "        titel = FileName.split('.csv')[0] + '_split%s.csv' % (splitnum)\n",
    "        \n",
    "        delete = FileWithItemsToDelete.loc[(FileWithItemsToDelete['Cat'] == Cat) & (FileWithItemsToDelete['pat'] == pat) & (FileWithItemsToDelete['meting'] == met) & (FileWithItemsToDelete['oef'] == oef) & (FileWithItemsToDelete['Split'] == splitnum)]\n",
    "        if delete.empty == False:\n",
    "            print('Delete this one')\n",
    "            continue\n",
    "            \n",
    "        adjust = FileWithItemsToAdjust.loc[(FileWithItemsToAdjust['Cat'] == Cat) & (FileWithItemsToAdjust['pat'] == pat) & (FileWithItemsToAdjust['meting'] == met) & (FileWithItemsToAdjust['oef'] == oef) & (FileWithItemsToAdjust['split'] == splitnum)]\n",
    "        if adjust.empty == False:\n",
    "            \n",
    "            NewBegin = adjust['begin'].values[0]\n",
    "            NewEnd = adjust['eind'].values[0]\n",
    "            \n",
    "            if NewBegin == 0:\n",
    "                NewBegin = start\n",
    "            if NewEnd == 0:\n",
    "                NewEnd = end\n",
    "            \n",
    "            plaatje = origdata[NewBegin:NewEnd]\n",
    "            print('Gecorigeerd')\n",
    "        \n",
    "        \n",
    "        SplitAgain = FileWithItemsToSplitAgain.loc[(FileWithItemsToSplitAgain['Cat'] == Cat) & (FileWithItemsToSplitAgain['Pat'] == pat) & (FileWithItemsToSplitAgain['Meting'] == met) & (FileWithItemsToSplitAgain['Oef'] == oef) & (FileWithItemsToSplitAgain['Split'] == splitnum)]\n",
    "        if SplitAgain.empty == False:\n",
    "            NewBegin = SplitAgain['Begin1'].values[0]\n",
    "            NewEnd2 = SplitAgain['Eind2'].values[0]\n",
    "            \n",
    "            if NewBegin == 0:\n",
    "                NewBegin = start\n",
    "            if NewEnd2 == 0:\n",
    "                NewEnd2 = end\n",
    "            \n",
    "            Plaatje1 = origdata[NewBegin:SplitAgain['Eind1'].values[0]]\n",
    "            Plaatje2 = origdata[SplitAgain['Begin2'].values[0]:NewEnd2]\n",
    "            \n",
    "            Plaatje1.to_csv('/datc/ortho/Cleaning/Step2 - testset/%s' % FileName.split('.csv')[0] + '_split%s.csv' % (splitnum+10), index=False, header=False)\n",
    "            Plaatje2.to_csv('/datc/ortho/Cleaning/Step2 - testset/%s' % FileName.split('.csv')[0] + '_split%s.csv' % (splitnum+11), index=False, header=False)\n",
    "            print('Splitted a splitted plaatje')\n",
    "            continue\n",
    "\n",
    "        \n",
    "#         xlist = plaatje[x]\n",
    "#         ylist = plaatje[y]\n",
    "#         zlist = plaatje[z]\n",
    "\n",
    "#         fig = plt.figure()\n",
    "#         plt.title(titel)\n",
    "#     #         plt.ylim((-180,180))\n",
    "#         plt.plot(xlist, color = 'red')\n",
    "#         plt.plot(ylist, color = 'blue')\n",
    "#         plt.plot(zlist, color = 'green')\n",
    "#         plt.legend()\n",
    "        print('Normal')\n",
    "        plaatje.to_csv('/datc/ortho/Cleaning/Step2 - testset/%s' % titel, index=False, header=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "FileWithItemsToDelete =pd.read_csv('./Corrections/Split to delete.csv', sep=';')\n",
    "FileWithItemsToAdjust =pd.read_csv('./Corrections/Split splitted.csv', sep=';')\n",
    "FileWithItemsToSplitAgain =pd.read_csv('./Corrections/Split non splitted.csv', sep=';')\n",
    "\n",
    "# MetaData = pd.read_csv('AllMetaData - All.csv')\n",
    "MetaData = pd.read_csv('Metadata Testset.csv')\n",
    "\n",
    "Files = MetaData['FileName'].apply(lambda x: x.split('/')[5])\n",
    "\n",
    "\n",
    "# x, y, z = (\"thorax_r_x\",\"thorax_r_y\", \"thorax_r_z\")\n",
    "# x, y, z = (\"clavicula_r_x\", \"clavicula_r_y\", \"clavicula_r_z\")\n",
    "# x, y, z = (\"scapula_r_x\", \"scapula_r_y\", \"scapula_r_z\")\n",
    "x, y, z = (\"humerus_r_x\", \"humerus_r_y\", \"humerus_r_z\")\n",
    "# VisualizeItemsCleaned(Files, x, y, z)\n",
    "for index, row in MetaData.iterrows():\n",
    "\n",
    "    VisualizeItemCleaned(row, x, y, z)\n",
    "    \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "Sort all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  4 13 2 22 0\n",
      "error:  4 13 1 22 0\n"
     ]
    }
   ],
   "source": [
    "def alpha(file):\n",
    "#     print('alpha')\n",
    "    copyfile(datc + file, enddir + 'alpha/' + file)\n",
    "    return\n",
    "    \n",
    "def bravo(file):\n",
    "#     print('bravo')\n",
    "    copyfile(datc + file, enddir + 'bravo/' + file)\n",
    "    return\n",
    "    \n",
    "def charlie(file):\n",
    "#     print('charlie')\n",
    "    copyfile(datc + file, enddir + 'charlie/' + file)\n",
    "    return\n",
    "    \n",
    "def delta(file):\n",
    "#     print('delta')\n",
    "    copyfile(datc + file, enddir + 'delta/' + file)\n",
    "    return\n",
    "    \n",
    "def echo(file):\n",
    "#     print('echo')\n",
    "    copyfile(datc + file, enddir + 'echo/' + file)\n",
    "    return\n",
    "\n",
    "enddir = '/datc/ortho/Cleaned oef/testset/'\n",
    "\n",
    "datc = '/data/ortho/testset/'\n",
    "\n",
    "for file in listdir(datc):\n",
    "    if 'meting' not in file:\n",
    "        continue\n",
    "    location = file\n",
    "    splitted = file.split('.')[0].split('_')\n",
    "    Cat = int(splitted[0].split('Cat')[1])\n",
    "    pat = int(splitted[1].split('pat')[1])\n",
    "    met = int(splitted[2].split('meting')[1])\n",
    "    oef = int(splitted[3].split('oef')[1])\n",
    "    try:\n",
    "        split = int(splitted[4].split('split')[1])\n",
    "    except(IndexError):\n",
    "        split = 0\n",
    "#     print(location)\n",
    "#     break\n",
    "\n",
    "    \n",
    "    if Cat == 1:\n",
    "        if oef in [2, 3]:\n",
    "            alpha(location)\n",
    "        elif oef in [4, 5]:\n",
    "            bravo(location)\n",
    "        elif oef in [6,7]:\n",
    "            charlie(location)\n",
    "        elif oef in [8,9]:\n",
    "            delta(location)\n",
    "        elif oef in [10,11]:\n",
    "            echo(location)\n",
    "        else:\n",
    "            print('error: ', Cat, pat, met, oef, split)\n",
    "            \n",
    "    if Cat == 1:\n",
    "        if oef in [2, 3]:\n",
    "            alpha(location)\n",
    "        elif oef in [4, 5]:\n",
    "            bravo(location)\n",
    "        elif oef in [6,7]:\n",
    "            charlie(location)\n",
    "        elif oef in [8,9]:\n",
    "            delta(location)\n",
    "        elif oef in [10,11]:\n",
    "            echo(location)\n",
    "        else:\n",
    "            print('error: ', Cat, pat, met, oef, split)\n",
    "    \n",
    "    if Cat == 2:\n",
    "        if oef in [2, 3]:\n",
    "            alpha(location)\n",
    "        elif oef in [4, 5]:\n",
    "            bravo(location)\n",
    "        elif oef in [6,7]:\n",
    "            charlie(location)\n",
    "        elif oef in [8,9]:\n",
    "            delta(location)\n",
    "        elif oef in [10,11]:\n",
    "            echo(location)\n",
    "        else:\n",
    "            print('error: ', Cat, pat, met, oef, split)\n",
    "    \n",
    "    if Cat == 3:\n",
    "        if oef in [2]:\n",
    "            alpha(location)\n",
    "        elif oef in [3]:\n",
    "            bravo(location)\n",
    "        elif oef in [4]:\n",
    "            charlie(location)\n",
    "        elif oef in [5]:\n",
    "            delta(location)\n",
    "        elif oef in [6]:\n",
    "            echo(location)\n",
    "        else:\n",
    "            print('error: ', Cat, pat, met, oef, split)\n",
    "    \n",
    "    if Cat == 4:\n",
    "        if oef in [2, 3, 4, 5]:\n",
    "            alpha(location)\n",
    "        elif oef in [6, 7, 8, 9]:\n",
    "            bravo(location)\n",
    "        elif oef in [10, 11, 12, 13]:\n",
    "            charlie(location)\n",
    "        elif oef in [14, 15, 16, 17]:\n",
    "            delta(location)\n",
    "        elif oef in [18, 19, 20, 21]:\n",
    "            echo(location)\n",
    "        else:\n",
    "            print('error: ', Cat, pat, met, oef, split)\n",
    "#     print(Cat, pat, met, oef, split)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
